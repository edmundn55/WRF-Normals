{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.core.options.set_options at 0x7f3bc0bcf250>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import cftime\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os, re, glob,datetime\n",
    "# Set global option\n",
    "xr.set_options(keep_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_for_large_data(raw_data):\n",
    "    \"\"\"\n",
    "    Function: Compute monthly or seasonal normals for wrfavg/*monthly*.nc by each data variable separately\n",
    "    \n",
    "    Input: raw_data as xarray dask dataset \n",
    "    \n",
    "    Output: xarray dataset \n",
    "    \"\"\"\n",
    "# Build empty dictionary\n",
    "    raw_dataarray={}\n",
    "# Compute normals by variables\n",
    "    for var in list(raw_data.data_vars):\n",
    "# Skip for times\n",
    "        if 'Times' in var:\n",
    "            pass\n",
    "        else:\n",
    "            raw_dataarray[var]=raw_data[var].compute()\n",
    "# Merge dataarrays back into 1 dataset\n",
    "    first_loop=True\n",
    "    for key in raw_dataarray.keys():\n",
    "        if first_loop:\n",
    "            output=raw_dataarray[key]\n",
    "            first_loop=False\n",
    "        else:\n",
    "            output=xr.merge([output,raw_dataarray[key]])\n",
    "# Add attributes back to output\n",
    "    for item in raw_data.attrs.items():\n",
    "        output.attrs[item[0]]=item[1]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nth_word_custom_delimiter(string, delimiter, n):\n",
    "    \"\"\"\n",
    "    Function: break strings by delimiter and grab nth element\n",
    "    \n",
    "    Input: full parameter of simulations\n",
    "    \n",
    "    Output: nth element in the parameter\n",
    "    \"\"\"\n",
    "# Split string by delimiter\n",
    "    words = string.split(delimiter)\n",
    "# Grab nth element in the string\n",
    "    if 1 <= n <= len(words):\n",
    "        return words[n-1]\n",
    "    else:\n",
    "        return \"Invalid value of N.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_parameter(dir_input):\n",
    "    \"\"\"\n",
    "    Function: Extract parameter to build nested directory and start year from directory and stepfile\n",
    "              based on types\n",
    "    \n",
    "    Input: Folder directory as strings\n",
    "    1) WRFTools*\n",
    "    or\n",
    "    2) <parameter>_<start year>\n",
    "    \n",
    "    Output: nested directory and start year as strings\n",
    "    \"\"\"\n",
    "# Extract info based on directory type\n",
    "# Start year from stepfile \n",
    "    time=open(dir_input+'stepfile')\n",
    "    lines=time.readlines()\n",
    "    start_year=lines[0][0:4]\n",
    "    if 'WRFTools' in dir_input:\n",
    "# Path for WRFTools simulations\n",
    "        par_start=dir_input.find('WRFTools')\n",
    "        path='WRFTools/'+dir_input[par_start+9:-1]                      # Nested directory\n",
    "        scen=''                                                         # Empty for WRFTools\n",
    "    else:\n",
    "# Path of other simulations \n",
    "        par_start=dir_input.find('wrf/')+4\n",
    "        par_end=dir_input.find(start_year)-1\n",
    "        full_par=dir_input[par_start:par_end]\n",
    "        force_d=get_nth_word_custom_delimiter(full_par,'_',1)            # Forcing dataset\n",
    "        scen=get_nth_word_custom_delimiter(full_par,'_',2)               # Scenario\n",
    "        grid=get_nth_word_custom_delimiter(full_par,'_',3)               # Grid\n",
    "        if grid=='NA24':\n",
    "            grid='na24'\n",
    "        phys=get_nth_word_custom_delimiter(full_par,'_',4)               # Physical configuration\n",
    "        path=force_d+'/'+grid+'/'+phys+'/'\n",
    "    return path,start_year,scen,grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def climate_normals(dir_input,sub_dir='wrfavg',dir_ouput=None,freq='M'):\n",
    "# Info for function \n",
    "    \"\"\"\n",
    "    Function:Compute monthly or seasonal normals and create netcdf \n",
    "             from monthly average data\n",
    "                \n",
    "    Input arguments: \n",
    "    dir_input: directory of simulation folder\n",
    "    sub_dir: directory of subfolder where monthly average netcdfs are stored \n",
    "    dir_out: directory of folder for outputs, currently working directory by default\n",
    "    freq: Frequency for normals, M for Monthly, S for Seasonal\n",
    "    \"\"\"\n",
    "# Extract input info from directory\n",
    "    path,start_year,scen,grid=build_parameter(dir_input)\n",
    "# Open datasets with dask\n",
    "    raw_data={file.stem :xr.open_dataset(file,chunks={'time':-1},decode_times=False) for file in Path(dir_input).glob(sub_dir+'/*monthly.nc')}\n",
    "    \n",
    "# Compute Normals for each dataset\n",
    "    First_loop=True\n",
    "    for key in raw_data.keys():\n",
    "        print('\\n',key,'start')\n",
    "        data=raw_data[key]\n",
    "# Grab wrf subcategory\n",
    "        wrf_cat=get_nth_word_custom_delimiter(key,'_',1)\n",
    "# Convert time to datetime64\n",
    "        data['time'] = pd.date_range(start=start_year+'-01-01', periods=data.sizes['time'], freq='MS')\n",
    "\n",
    "# Find End Year    \n",
    "        if First_loop:\n",
    "            end_year=str(data.time[-1].values)[0:4]\n",
    "# Build output directory \n",
    "            if dir_ouput == None:\n",
    "                cwd_start=os.getcwd().find('/project')\n",
    "                cwd=os.getcwd()\n",
    "                out_dir=os.path.join(cwd[cwd_start::],path)\n",
    "            else:\n",
    "                out_dir=os.path.join(dir_ouput,path)\n",
    "# Check if directory exists and create if false\n",
    "            if os.path.exists(out_dir)==False:\n",
    "#                 os.makedirs(out_dir)\n",
    "                print(out_dir)\n",
    "            else:\n",
    "                print('Directory exists\\n')\n",
    "            First_loop=False\n",
    "# Build full path for output file\n",
    "# Check if file exists\n",
    "        if freq =='M' and os.path.isfile(out_dir+wrf_cat+'_'+scen+'_mon-norm-'+start_year+'-'+end_year+'.nc'):\n",
    "            print(key,'File exists\\n')\n",
    "        elif freq =='S' and os.path.isfile(out_dir+wrf_cat+'_'+scen+'_sea-norm-'+start_year+'-'+end_year+'.nc'):\n",
    "            print(key,'File exists\\n')\n",
    "# Ignore temporary file in folder\n",
    "        elif 'tmp_' in key:\n",
    "            print(key,'skip\\n')\n",
    "        else:\n",
    "# Group dataset by months or seasons and compute mean\n",
    "            if freq =='M':\n",
    "                data_norm=data.groupby('time.month').mean('time')\n",
    "            elif freq == 'S':\n",
    "                data_norm=data.groupby('time.season').mean('time')\n",
    "# Compute seasonal or monthly normals by dataarray for plev.nc\n",
    "            if 'plev' in key:\n",
    "                data_norm=normal_for_large_data(data_norm)\n",
    "            else:\n",
    "                pass\n",
    "# Create netcdf for monthly normals\n",
    "            if freq=='M':\n",
    "                data_norm.to_netcdf(out_dir+wrf_cat+'_'+scen+'_mon-norm-'+start_year+'-'+end_year+'.nc')\n",
    "            elif freq =='S':\n",
    "                data_norm.to_netcdf(out_dir+wrf_cat+'_'+scen+'_sea-norm-'+start_year+'-'+end_year+'.nc')\n",
    "            print('done\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
