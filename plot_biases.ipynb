{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.core.options.set_options at 0x7f7ff0a83110>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load packages\n",
    "import os,glob,sys\n",
    "import xesmf as xe\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "import cartopy.crs as crs\n",
    "import matplotlib\n",
    "from cartopy.feature import NaturalEarthFeature \n",
    "import cartopy.feature as cfeature\n",
    "import datetime\n",
    "from wrf import (getvar, interplevel, vertcross, \n",
    "                 CoordPair, ALL_TIMES, to_np,\n",
    "                 get_cartopy, latlon_coords,\n",
    "                 cartopy_xlim, cartopy_ylim,\n",
    "                 Constants,extract_vars)\n",
    "from matplotlib import pyplot as plt\n",
    "# Define global setting\n",
    "xr.set_options(keep_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nth_word_custom_delimiter(string, delimiter, n):\n",
    "    \"\"\"\n",
    "    Function: break strings by delimiter and grab nth element\n",
    "    \n",
    "    Input: full parameter of simulations\n",
    "    \n",
    "    Output: nth element in the parameter\n",
    "    \"\"\"\n",
    "# Split string by delimiter\n",
    "    words = string.split(delimiter)\n",
    "# Grab nth element in the string\n",
    "    if 1 <= n <= len(words):\n",
    "        return words[n-1]\n",
    "    else:\n",
    "        return \"Invalid value of N.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build curvilinear grids for netcdfs\n",
    "def build_wrf_gird(WRF_d,geo_file):\n",
    "    \"\"\"\n",
    "    Function: build x,y curvilinear grids from WRF input dataset and geo_em\n",
    "    Input: path for WRF dataset, path for geo_em file\n",
    "    Output: WRF netcdf with curvilinear grid in lat/lon, coordinate system for WRF24\n",
    "    \"\"\"\n",
    "    # Open geo_em file, get HGT var, cart_proj and lats and lons\n",
    "    geo=Dataset(geo_file)\n",
    "    HGT = getvar(geo,\"HGT_M\",timeidx=ALL_TIMES)\n",
    "    WRF_cart_proj = get_cartopy(HGT)\n",
    "    WRF_lats, WRF_lons = latlon_coords(HGT)\n",
    "    # Create WRF Projection\n",
    "    wrf_globe = crs.Globe(ellipse=None,\n",
    "                          semimajor_axis=Constants.WRF_EARTH_RADIUS,\n",
    "                          semiminor_axis=Constants.WRF_EARTH_RADIUS)\n",
    "    # Define a latitude/longitude coordinate system\n",
    "    wrf_xform_crs = crs.Geodetic(globe=wrf_globe)\n",
    "    # Open dataset\n",
    "    if '_mon_' in WRF_d: \n",
    "         WRF=xr.open_dataset(WRF_d,decode_times=False,chunks={'month':12})\n",
    "    elif '_sea_' in WRF_d:\n",
    "        WRF=xr.open_dataset(WRF_d,decode_times=False,chunks={'season':4})\n",
    "#     WRF=WRF_d\n",
    "    # Insert lat and lon for re-gridding\n",
    "    WRF_latlon=WRF.assign_coords({'lat':(('south_north','west_east'),WRF_lats.values),'lon':(('south_north','west_east'),WRF_lons.values)})\n",
    "    # Drop coordinate XTIME\n",
    "#     WRF_latlon=WRF_latlon.drop_vars(['XTIME'])\n",
    "    return WRF_latlon,WRF_cart_proj, wrf_xform_crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate to WRF24 grids\n",
    "def to_WRF_grid(WRF,WRF_proj,WRF_crs,obs_d=None):\n",
    "    \"\"\"\n",
    "    Function: Interpolate input dataset to WRF24 grid and perform remapping \n",
    "    Input: WRF xarray dataset with lat and lon,WRF porjection, WRF coordinate system, \n",
    "           Observation dataset\n",
    "           remap from polar to WRF24 for i.ie. Rutgers Northern Hemisphere 24 km Weekly Snow Cover Extent\n",
    "           or from WGS1984 to WRF24 for i.e. ERA5 Land\n",
    "    Output: netcdf with curvilinear grid in EPSG 4326\n",
    "    \"\"\"\n",
    "    # Grab parameters from WRF dataset\n",
    "    year_start=int(WRF.attrs['begin_date'][0:4])                          # Begin year\n",
    "    year_end=int(WRF.attrs['end_date'][0:4])                              # End year\n",
    "    \n",
    "    # For WRF output\n",
    "    if obs_d==None:\n",
    "        # Generate lat long based on WRF Projection\n",
    "        xform_pts = WRF_proj.transform_points(WRF_crs,to_np(WRF.lon),to_np(WRF.lat))\n",
    "        WRF_x = xform_pts[...,0]\n",
    "        WRF_y = xform_pts[...,1]\n",
    "        # insert lat and lon grids into dataset         \n",
    "        WRF_output=WRF.assign_coords({'lat':(('south_north','west_east'),WRF_y),'lon':(('south_north','west_east'),WRF_x)})\n",
    "        # build file name\n",
    "        wrf_cat=get_nth_word_custom_delimiter(WRF.attrs['description'],' ',1) # WRF category \n",
    "        freq=list(WRF.indexes)[0][0:3]                                        # Temporal frequency\n",
    "        par_full=WRF.attrs['experiment']\n",
    "        force_d=get_nth_word_custom_delimiter(par_full,'_',1)                 # Forcing dataset\n",
    "        scen=get_nth_word_custom_delimiter(par_full,'_',2)                    # Scenario\n",
    "        phys=get_nth_word_custom_delimiter(par_full,'_',4)                    # Physical configuration\n",
    "        grid='wrf24'                                                          # Grid\n",
    "        out_path=force_d+'/'+grid+'/'+phys+'/'\n",
    "        if os.path.exists(out_path)==False:\n",
    "            os.makedirs(out_path)\n",
    "        else:\n",
    "            print('Directory exists\\n')\n",
    "        outfile=os.path.join(out_path,'wrfplev3d_'+scen+'_'+freq+'-norm-'+str(year_start)+'-'+str(year_end)+'.nc')\n",
    "        if os.path.isfile(outfile):\n",
    "            print('File exists\\n')\n",
    "        else:\n",
    "            WRF_output.to_netcdf(outfile)\n",
    "        return WRF_output\n",
    "    else:\n",
    "    # Open dataset\n",
    "    # For rutger dataset\n",
    "        if 'rutgers' in obs_d:\n",
    "            obs_raw=xr.open_dataset(obs_d,chunks={'time':100})\n",
    "            \n",
    "    # For ERA5-Land dataset\n",
    "        elif 'era5l' in obs_d:\n",
    "            obs_raw=xr.open_mfdataset(obs_d).sortby('time')\n",
    "            # Rechunk dataset\n",
    "            obs_raw=obs_raw.chunk({'time':200,'latitude':200,'longitude':500})\n",
    "     #  For ERA5-Land dataset\n",
    "        elif 'era5pl' in obs_d:\n",
    "            obs_raw=xr.open_mfdataset(obs_d).sortby('time')\n",
    "            # Rechunk dataset\n",
    "            obs_raw=obs_raw.chunk({'time':60,'latitude':200,'longitude':200,'level':-1})\n",
    "    # For CERES dataset\n",
    "        elif 'CERES' in obs_d:\n",
    "            obs_raw=xr.open_mfdataset(obs_d).sortby('time')\n",
    "            # Rechunk dataset\n",
    "            obs_raw=obs_raw.chunk({'time':100,'lon':200,'lat':88})\n",
    "         # Rename lat/lon\n",
    "        if ('rutgers' in obs_d) or ('era5l' in obs_d):\n",
    "            obs_raw=obs_raw.rename({'latitude':'lat','longitude':'lon'})\n",
    "        # Generate normal for dataset\n",
    "        obs_norm=obs_raw.isel(time=(obs_raw.time.dt.date<datetime.date(2015+1,1,1))).groupby('time.month').mean('time')\n",
    "#         obs_norm=obs_raw.groupby('time.month').mean('time')\n",
    "#       obs_norm=obs_raw.isel(time=((obs_raw.time.dt.date>=datetime.date(2000,3,1))&(obs_raw.time.dt.date<=datetime.date(2014,12,1)))).groupby('time.season').mean('time')\n",
    "        # Mask missing value for Rutger dataset\n",
    "        if 'rutgers' in obs_d:\n",
    "            # Extract lat/lon as 2d numpy arrays\n",
    "            obs_lat=obs_norm.lat.values\n",
    "            obs_lon=obs_norm.lon.values.T\n",
    "            # Replace missing values with nan\n",
    "            new_lat=np.where(obs_lat>90,np.nan,obs_lat)\n",
    "            new_lon=np.where(obs_lon>180,np.nan,obs_lon)\n",
    "            obs_norm=obs_norm.assign_coords({'lat':(('x','y'),new_lat),'lon':(('x','y'),new_lon)})\n",
    "        # Regrid to WRF24\n",
    "        Regridder=xe.Regridder(obs_norm,WRF,'patch')\n",
    "        print('Regridding start')\n",
    "        obs_output_re=Regridder(obs_norm,keep_attrs=True)    #Keep attributes\n",
    "        # Transform to WRF Projection\n",
    "        xform_pts = WRF_proj.transform_points(WRF_crs,to_np(obs_output_re.lon.values),to_np(obs_output_re.lat.values))\n",
    "        obs_wrf_x = xform_pts[...,0]\n",
    "        obs_wrf_y = xform_pts[...,1]\n",
    "        obs_output_re=obs_output_re.assign_coords({'lat':(('south_north','west_east'),obs_wrf_y),\n",
    "                                                        'lon':(('south_north','west_east',),obs_wrf_x)})\n",
    "        return obs_output_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute biases and generate plots\n",
    "def find_outlier(obs_d,conus_d,new_d,newloc_d,geo_file,v_min,v_max,obs_src=None,par=None):\n",
    "    \"\"\"\n",
    "    Function: Compute biases and generate plot based on parameter chosen\n",
    "    Inputs: Observational, WRF-Conus, New, newloc xarray datasets regridded to WRF24\n",
    "            Observational dataset source (i.e. ERA5L/Rutger)\n",
    "            parameter to compare (i.e. snow cover)\n",
    "            Land mask as 2d numpy array\n",
    "    Output: Bias plots\n",
    "    \"\"\"\n",
    "    # Define seasons\n",
    "    seasons=['DJF','MAM','JJA','SON'] \n",
    "    # Choose variable from xarray datasets\n",
    "    if par=='SNOWC':\n",
    "        if obs_src=='ERA5L':\n",
    "            obs_raw=obs_d.snowc/100\n",
    "        elif obs_src=='Rutger':\n",
    "            obs_raw=obs_d.snow_cover_extent\n",
    "        conus_raw=conus_d.SNOWC\n",
    "        new_raw=new_d.SNOWC\n",
    "        newloc_raw=newloc_d.SNOWC\n",
    "    elif par=='SW_D':\n",
    "        if obs_src=='ERA5L':\n",
    "            obs_raw=obs_d.ssrd/86400 # convert J/m^2 to W/m^-2\n",
    "        elif obs_src=='CERES':\n",
    "            obs_raw=obs_d.sfc_sw_down_all_mon\n",
    "        conus_raw=conus_d.ACSWDNB\n",
    "        new_raw=new_d.ACSWDNB\n",
    "        newloc_raw=newloc_d.ACSWDNB\n",
    "    elif par=='SW_U':\n",
    "        if obs_src=='ERA5L':\n",
    "            obs_raw=(obs_d.ssrd-obs_d.ssr)/86400 # convert J/m^2 to W/\n",
    "        elif obs_src=='CERES':\n",
    "            obs_raw=obs_d.sfc_sw_up_all_mon\n",
    "        conus_raw=conus_d.ACSWUPB\n",
    "        new_raw=new_d.ACSWUPB\n",
    "        newloc_raw=newloc_d.ACSWUPB\n",
    "    elif par=='ALB':\n",
    "        if obs_src=='ERA5L':\n",
    "            obs_raw=(obs_d.ssrd-obs_d.ssr)/obs_d.ssrd/86400\n",
    "        elif obs_src=='CERES':\n",
    "            obs_raw=obs_d.sfc_sw_up_all_mon/obs_d.sfc_sw_down_all_mon\n",
    "        conus_raw=conus_d.ACSWUPB/conus_d.ACSWDNB\n",
    "        new_raw=new_d.ACSWUPB/new_d.ACSWDNB\n",
    "        newloc_raw=newloc_d.ACSWUPB/newloc_d.ACSWDNB\n",
    "    # Store WRF as dictionary\n",
    "    WRF_raw={'CONUS':conus_raw,'NEW':new_raw,'NEWLOC':newloc_raw}\n",
    "    # Compute biases and store in new dictionary\n",
    "    WRF_biases={}\n",
    "    # Extract land mask (0: water and 1: for land)\n",
    "    LM = xr.open_dataset(geo_file)\n",
    "    LM = LM.LANDMASK.values[0]\n",
    "    # get shape for empty array\n",
    "    N,M=LM.shape\n",
    "    # Creat empty for storing lower/upper quantile and  points with data\n",
    "    WRF_with_data=np.empty([4,3])\n",
    "    WRF_all_pts=np.empty([3,4,N,M])\n",
    "    for j,physics in enumerate(WRF_raw.keys()):\n",
    "        WRF_biases[physics]=WRF_raw[physics]-obs_raw\n",
    "        # Find values for seasonal quantiles\n",
    "        print('Calculating for',physics,'....\\n')\n",
    "        WRF_all_pts[j]=WRF_biases[physics].values\n",
    "        for i,s in enumerate(seasons):\n",
    "            WRF_all_pts[j,i][LM==0]=np.nan\n",
    "            WRF_biases[physics][i]= WRF_all_pts[j,i]\n",
    "            # Find the total number of points with data\n",
    "            WRF_with_data[i,j]=np.sum(~(np.isnan(WRF_all_pts[j,i])))\n",
    "            # Compute % of outliers for lower and upper bound\n",
    "            WRF_outlier_L=np.nansum(WRF_all_pts[j,i]<v_min[i])/WRF_with_data[i,j]*100\n",
    "            WRF_outlier_U=np.nansum(WRF_all_pts[j,i]>v_max[i])/WRF_with_data[i,j]*100\n",
    "        # Print results\n",
    "            print(\"{:<80}\".format('% points outside range (lower,upper,total) for var '+par+':'+ \\\n",
    "                ', season '+s+', model '+physics+ \\\n",
    "                ' ='),\"%.2f\"%(WRF_outlier_L),\"%.2f\"%(WRF_outlier_U),\"%.2f\"%(WRF_outlier_L+WRF_outlier_U),'\\n')\n",
    "    return WRF_biases,WRF_all_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_plots(WRF_biases,WRF_proj,WRF_all_pts,v_min,v_max,obs=None,par=None,par_s=None):\n",
    "    # Set variables for plots\n",
    "    seasons=['DJF','MAM','JJA','SON'] \n",
    "    season_name=['Winter','Spring','Summer','Fall']\n",
    "    # Set natural feature\n",
    "    states = cfeature.NaturalEarthFeature(\n",
    "        category='cultural',\n",
    "        name='admin_1_states_provinces_lines',\n",
    "        scale='50m',\n",
    "        facecolor='none')\n",
    "    land_edge_color=[0.55, 0.55, 0.55]\n",
    "    # Replace inf with nan for calculation\n",
    "    WRF_all_pts[WRF_all_pts==np.inf]=np.nan\n",
    "    # Plotting\n",
    "    fig = plt.figure(figsize=(28,42))\n",
    "    # Add season titles\n",
    "    for i,s in enumerate(seasons):\n",
    "        # Add season name\n",
    "        fig.text(-0.04,0.14+(3-i)*0.24,season_name[i], ha='center',va='center',rotation=90,fontsize=48)\n",
    "        # Set conditions for colorbar if 0 is not in range\n",
    "        if v_min[i]>=0:\n",
    "            c_norm = matplotlib.colors.TwoSlopeNorm(vmin=-0.2,vcenter=0.0,vmax=v_max[i]) \n",
    "        elif v_max[i]<=0:\n",
    "            c_norm = matplotlib.colors.TwoSlopeNorm(vmin=v_min[i],vcenter=0.0,vmax=0.2)\n",
    "        else:\n",
    "            c_norm = matplotlib.colors.TwoSlopeNorm(vmin=v_min[i],vcenter=0.0,vmax=v_max[i])\n",
    "        for j,physics in enumerate(WRF_biases.keys()):\n",
    "            # choose plot location and projection\n",
    "            ax = fig.add_subplot(4,3,1+j+3*i,projection=WRF_proj)\n",
    "            # Add Natural features\n",
    "            ax.add_feature(cfeature.LAND,linewidth=1,edgecolor=land_edge_color,facecolor=\"none\",zorder=3) \n",
    "            ax.add_feature(states,linewidth=1,edgecolor=land_edge_color,facecolor=\"none\",zorder=3)   \n",
    "            ax.add_feature(cfeature.LAKES,linewidth=1,edgecolor=land_edge_color,facecolor=\"none\",zorder=3)\n",
    "            ax.add_feature(cfeature.BORDERS,linewidth=1,edgecolor=land_edge_color,facecolor=\"none\",zorder=3)\n",
    "            # generate plots\n",
    "            S=WRF_biases[physics].sel(season=s).plot.pcolormesh(x='lon',y='lat',ax=ax,       # x, y axes\n",
    "                                                                add_colorbar=False,          # remove colorbar\n",
    "                                                                cmap='bwr',                  # colors\n",
    "                                                                norm=c_norm)                 # \n",
    "                                                                \n",
    "            # Remove title\n",
    "            ax.set_title('')\n",
    "\n",
    "            # Calculate and show mean (mean over space) seasonal bias\n",
    "            fig.text(0.03+0.335*j,0.783-i*0.24,\"%.2f\"%round(np.nanmean(np.abs(WRF_all_pts[j,i]),dtype=float),2), \\\n",
    "                ha='center',va='center',fontsize=40)   \n",
    "            print(physics,s,'done')\n",
    "        # Add colorbars\n",
    "        cbar_ax = fig.add_axes([0.27,0.745-i*0.24,0.465,0.013])     \n",
    "        cbar = plt.colorbar(S,cax=cbar_ax,orientation=\"horizontal\",\n",
    "                            extend='both') \n",
    "        tick_locator = matplotlib.ticker.MaxNLocator(nbins=5,\n",
    "                                                    min_n_ticks=6,\n",
    "                                                    symmetric=True)\n",
    "        cbar.locator = tick_locator\n",
    "        cbar.update_ticks()        \n",
    "        cbar.ax.tick_params(labelsize=35)\n",
    "        cbar.ax.set_xscale('linear')\n",
    "    # Set figure layout and add x and y labels and titles, etc \n",
    "    fig.tight_layout(pad=0.0,w_pad=2.0,h_pad=0)     \n",
    "    # Add overall plot title\n",
    "    fig.text(0.5,1.02,par+' Average Seasonal Bias of WRF (2000-2014) as Compared to '+obs,ha='center',va='center',fontsize=40)\n",
    "        \n",
    "    # Add plot titles and sub-titles\n",
    "    vx=[0.17,0.50,0.84]\n",
    "    # title y location\n",
    "    vy_t= 0.975\n",
    "    # suptitle y location\n",
    "    vy_supt = -0.01     \n",
    "    for i, physics in enumerate(WRF_biases.keys()):\n",
    "        fig.text(vx[i],vy_t,r'$\\overline{({%s}_{%s}-{%s}_{Ob})}$' %(par_s,physics,par_s),\n",
    "                 ha='center',va='center',fontsize=35)\n",
    "        fig.text(vx[i],vy_supt,physics+' '+par_s+' Abs. Bias',ha='center',va='center',fontsize=48)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccia_edmundn",
   "language": "python",
   "name": "ccia_edmundn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
