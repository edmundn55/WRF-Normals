{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.core.options.set_options at 0x7f1670f630a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load packages\n",
    "# import numpy as np\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import cftime\n",
    "import pandas as pd\n",
    "import os, re, glob, datetime\n",
    "# Set global option\n",
    "xr.set_options(keep_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nth_word_custom_delimiter(string, delimiter, n):\n",
    "    \"\"\"\n",
    "    Function: cut string by delimiter and grab nth element\n",
    "    \n",
    "    Input: string\n",
    "    \n",
    "    Output: nth element in the string\n",
    "    \"\"\"\n",
    "    # Split string by delimiter\n",
    "    words = string.split(delimiter)\n",
    "    # Grab nth element in the string\n",
    "    if 1 <= n <= len(words):\n",
    "        return words[n-1]\n",
    "    else:\n",
    "        return \"Invalid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_parameter(data):\n",
    "    \"\"\"\n",
    "    Function: Extract parameter to build nested directory from xarray dataset\n",
    "    \n",
    "    Input: Xarray dataset\n",
    "    1) WRFTools*\n",
    "    or\n",
    "    2) <parameter>_<start year>\n",
    "    \n",
    "    Output: nested directory and scenario as string\n",
    "    \"\"\"\n",
    "    # Build paths for different folder types\n",
    "    # For WRFTools\n",
    "    if 'WRFTools' in data.attrs['experiment']:\n",
    "        par = get_nth_word_custom_delimiter(data.attrs['experiment'],'_',2) \n",
    "        path = 'WRFTools/'+par+'/na24/'\n",
    "        scen = ''                                                            # Empty for WRFTools\n",
    "\n",
    "    else:\n",
    "    # Path of other simulations \n",
    "        full_par = data.attrs['experiment']\n",
    "        force_d = get_nth_word_custom_delimiter(full_par,'_',1)              # Forcing dataset\n",
    "        scen = get_nth_word_custom_delimiter(full_par,'_',2)                 # Scenario\n",
    "        grid = get_nth_word_custom_delimiter(full_par,'_',3)                 # Grid\n",
    "        if grid == 'NA24':                                                   # convert to small case\n",
    "            grid = 'na24'\n",
    "        phys = get_nth_word_custom_delimiter(full_par,'_',4)                 # Physical configuration\n",
    "        # Fix issues with directory format -YYYY\n",
    "        if phys[-5] == '-':\n",
    "            phys = phys[0:-5]\n",
    "        else:\n",
    "            pass\n",
    "        path = force_d+'/'+grid+'/'+phys+'/'\n",
    "    return path,scen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def climate_normals(dir_input, freq, sub_dir='wrfavg', dir_ouput=None):\n",
    "    # Info for function \n",
    "    \"\"\"\n",
    "    Function:Compute monthly or seasonal normals and create netcdf \n",
    "             from monthly average data\n",
    "                \n",
    "    Input arguments: \n",
    "    dir_input: directory of simulation folder\n",
    "    sub_dir: directory of subfolder where monthly average netcdfs are stored \n",
    "    dir_out: directory of folder for outputs, currently working directory by default\n",
    "    freq: Frequency for normals, month = Monthly, season = Seasonal \n",
    "    \"\"\"\n",
    "   \n",
    "    # Open datasets with dask\n",
    "    raw_data = {file.stem :xr.open_dataset(file,chunks={'time':-1},decode_times=False) for file in Path(dir_input).glob(sub_dir+'/*monthly.nc')}\n",
    "    \n",
    "    # Compute Normals for each dataset\n",
    "    first_loop = True\n",
    "    for key in raw_data.keys():\n",
    "        print('\\n',key,freq,'start')\n",
    "        data = raw_data[key]\n",
    "        # Grab first year\n",
    "        start_year = data.attrs['begin_date'][0:4]\n",
    "        # Grab wrf subcategory\n",
    "        wrf_cat = get_nth_word_custom_delimiter(data.attrs['description'],' ',1)\n",
    "        # Convert time to datetime64\n",
    "        data['time'] = pd.date_range(start=start_year+'-01-01', periods=data.sizes['time'], freq='MS')\n",
    "\n",
    "        # Find End Year    \n",
    "        if first_loop:\n",
    "            end_year = str(data.time[-1].values)[0:4]\n",
    "            path, scen = build_parameter(data)\n",
    "            # Build output directory \n",
    "            if dir_ouput != None:\n",
    "                out_dir = os.path.join(dir_ouput,path)\n",
    "            else:\n",
    "                out_dir = path\n",
    "            # Check if directory exists and create if false\n",
    "            if os.path.exists(out_dir) == False:\n",
    "                os.makedirs(out_dir)\n",
    "            else:\n",
    "                print('Directory exists\\n')\n",
    "                print(out_dir)\n",
    "            first_loop = False\n",
    "        # Build full path for output file\n",
    "        # For missing scenario\n",
    "        if scen == '':\n",
    "            out_file = out_dir+wrf_cat+'_'+freq[0:3]+'-norm-'+start_year+'-'+end_year+'.nc'\n",
    "        else:\n",
    "            out_file = out_dir+wrf_cat+'_'+scen+'_'+freq[0:3]+'-norm-'+start_year+'-'+end_year+'.nc'\n",
    "        # Check if file exists\n",
    "        if os.path.isfile(out_file):\n",
    "            print(out_file,'File exists\\n')\n",
    "\n",
    "        # Ignore temporary file in folder\n",
    "        elif 'tmp_' in key:\n",
    "            print(key,'skip\\n')\n",
    "        else:\n",
    "            # Group dataset by months or seasons and compute mean\n",
    "            data_norm = data.groupby('time.'+freq).mean('time')\n",
    "            # Export normals as netcdfs\n",
    "            data_norm.to_netcdf(out_file)\n",
    "        print('done\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
